# BigGAN and Musescore and FFmpeg/SoX and Python hacks: Oh My!
A generative neural network script written by <a href="https://github.com/msieg">msieg</a> has been adapted to add video and audio enhancement to the resulting video.

An 8D audio generator has been written in Python to create an "audio moving from ear to ear" illusion that was inspired by the Pokemon Mystery Dungeon: Explorers of Sky soundtrack (it's very tasteful when used right).

The music is in the form of two similar Musescore `.mscz` files, which contain parts within them that can be exported to wav and mixed with FFmpeg, SoX, and Python to compensate for Musescore audio output quality (I'm too poor to buy Sibelius)

The music within this repository is entitled "Impassive", and is meant to symbolize the loss of feeling as time passes from a distressing series of events. More expicitly, the vibraphone represent the color of the human experience, where the marimbas which introduce themselves later on resemble the dryness and desperation that accompanies traumatic experiences. The video generated by the generative adversarial network attempts to capture the confusion of being in a world fueled by <a href"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2683754/">dissociation</a> and lack of emotional permanence. The mushrooms were added because I lik shrooms.

[![Alt text](https://img.youtube.com/vi/L7R-yBZ5QYc/0.jpg)](https://www.youtube.com/watch?v=L7R-yBZ5QYc)

For a surface-level explaination of BigGAN, see the following medium.com article: 
<a href="https://towardsdatascience.com/the-deep-music-visualizer-using-sound-to-explore-the-latent-space-of-biggan-198cd37dac9a">The Deep Music Visualizer: Using sound to explore the latent space of BigGAN</a>

More examples: https://www.instagram.com/deep_music_visualizer/

## Installation

With conda installed, run the following (pytorch gives issues when installed with pip for some reason)
```zsh
git clone https://github.com/msieg/deep-music-visualizer.git
cd deep-music-visualizer
pip install conda
conda env create -f environment.yml
```

If you are on linux, you may also need to run:

```zsh
apt-get update
apt-get install ffmpeg
apt-get install libsndfile1
```

## How to run

See original repository for details on `visualize.py` parameters.

Using Musescore, export the score parts (Vibe, Bells, and Marimba) from the two .mscz files to the `./media` directory of the repository, then run either `make gan build` or one of the following to compile the music and audio into a music video.

```zsh
# construct a 512x512 neural network audio visualization of the unaltered audio (Impassive.wav)
# *Note: will take ~3.3 hours on an average desktop without CUDA cores
make gan

# using preexisting 512x512 video, apply video and audio filters
# (equivalent to 'make audio video')
make build

# mix audio tracks together and add effects to result in an
# Impassive-Wet.wav file to be added to the video
make audio

# use the generated 512x512 video to create a 1920x1080 altered version
# of the video, mirroring over the y-axis and on the outer edges as well
# as adding other effects. Runs 'make merge' to import generated audio
make video

# mix audio, then merge the audio to 'Impassive.mkv'
# (equivalent to 'make audio merge')
make amerge

# see ./Makefile for additional details
```
